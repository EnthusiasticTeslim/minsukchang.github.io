<!DOCTYPE html>
<head>
    <!-- styling-->
    <meta charset="utf-8">
	<link href='main.css' type='text/css' rel='stylesheet'/>
	<link href='http://fonts.googleapis.com/css?family=Noto+Sans|Open+Sans' rel='stylesheet' type='text/css'>
    
    <!-- metadata-->
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <!-- Bootstrap Core CSS-->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    
    <!-- more/less buttons-->
	<script type="text/javascript">
		$( document ).ready(function() {
			$('.readmore').hide()
			$('.lessbutton').hide()
			$('.morebutton').on("click", function(event) {
				$(this).hide();
				$("#" + event.target.id + "_content").show()
				$("#" + event.target.id + "_less").show()
			});

			$('.lessbutton').on("click", function(event) {
				$(this).hide();
				$("#" + event.target.id.split("_")[0] + "_content").hide()
				$("#" + event.target.id.split("_")[0]).show()
			});
		});
    </script>
</head>

<body>
	<div class="container">
        <!-- bio row -->
		<div class="row">
            <div class="col-md-2"> </div>
            <div class="col-md-8 mt-10 ml-10">
                <div class="row">
                    <div class="col-md-4">    
                        <span>
                            <img id="profilepic" class="img-fluid rounded-circle mx-auto mb-1" src="img/me2.png" alt="Minsuk's profile picture">
                        </span>                      
                        <div id=social class="mx-auto">
                            <a href="mailto: minsuk@minsukchang.com"><i class="fas fa-2x fa-envelope"></i></a> 
                            <a href="https://scholar.google.co.uk/citations?user=1j2nBpoAAAAJ"><i class="fas fa-2x fa-graduation-cap"></i></a>
                            <a href="https://github.com/minsukchang"><i class="fab fa-2x fa-github"></i></a>
                            <a href="https://twitter.com/minsuk_chang"><i class="fab fa-2x fa-twitter"></i></a>
                            <a href="https://facebook.com/minsuk.chang"><i class="fab fa-2x fa-facebook-f"></i></a>
                            <a href="https://linkedin.com/in/minsuk"><i class="fab fa-2x fa-linkedin"></i></a>
                        </div>
                    </div>                   
                    <div class="col-md-8">    
                        <div class="myname">Minsuk Chang</div>
                        <p class="intro">I'm a <a href="https://cs.kaist.ac.kr/">Computer Science</a> PhD student in the <a href="https://www.kixlab.org/">KIXLAB</a> at 
                            <a href="https://www.kaist.ac.kr">KAIST</a> advised by <a href="https://juhokim.com/">Juho Kim</a>. Here's my <a href="files/CV_minsukchang_2018_USLetter.pdf"> CV (pdf).</a>  </p>
                            <p class="intro">
                            My work in HCI focuses on techniques for discovering, capturing, and structuring user context in large-scale web data to create novel learning
                            opportunities in the wild. 

                                                        
                          
                    </div>  
                </div> 
            </div>
            <div class="col-md-2"> </div>
        </div>
        <!-- bio row END-->
        
        <!-- news row -->
        <div class="row">
            <div class="col-md-2"> </div>
            <div class="col-md-8"> 
                <div class="pub">Latest News</div>
                <span class="date">Jan 2019 :</span><span class="news"> Will be spending the summer at <a href="https://www.microsoft.com/en-us/research/group/information-and-data-sciences/">Microsoft AI + Research </a> @ Redmond. Super excited!</span><br>
                <span class="date">Dec 2018 :</span><span class="news"> Voice interfaces for video tutorials I worked on during the summer @ <a href="https://research.adobe.com">Adobe Research</a> has been conditionally accepted to <a href="https://chi2019.acm.org/">CHI 2019</a>. See you @ Glasgow!</span><br>
                <span class="date">Nov 2018 :</span><span class="news"> Started winter internship at <a href="https://www.autodeskresearch.com/groups/user-interface">Autodesk Research @ Toronto!</a></span><br>
                
                <span class="morebutton" id="article00"> More News </span>
                <span class="readmore" id="article00_content">

                <span class="date">Oct 14-19 2018 :</span><span class="news"> Traveling to <a href="https://uist.acm.org/uist2018/">UIST 18 @ Berlin</a>. SV'ing again!</span> <br>
                <span class="date">Aug 22 2018 :</span><span class="news"> Visiting <a href="https://www.cs.ubc.ca/nest/imager/hci.php">University of British Columbia </a>to give a talk on voice+video interfaces. </span><br>
                <span class="date">Jun 2018 :</span><span class="news"> Started research internship at <a href="https://research.adobe.com">Adobe Research @ Seattle</a>! Seattle people, let's meet!. </span><br>
                <span class="date">Apr 2018 :</span><span class="news"> at <a href="https://chi2018.acm.org/">CHI 2018</a> in Montreal, Quebec! Presenting RecipeScape on thursday morning. </span><br>
                <span class="date">Apr 2018 :</span><span class="news"> Will present RecipeScape at <a href="http://sigchi.kr/">SIGCHI Korea Local Chapter</a> 2018 Spring Academic Workshop </span><br>
                <span class="date">Mar 2018 :</span><span class="news"> Invited to <a href="https://sensemakingchi2018.com/">CHI 2018 Sensemaking Workshop.</a> </span><br>
                <span class="date">Mar 2018 :</span><span class="news"> Excited to spend the summer at <a href="https://research.adobe.com">Adobe Research @ Seattle! </a> </span><br>
                <span class="date">Feb 2018 :</span><span class="news"> Presented a poster on RecipeScape at <a href="https://hci.kaist.ac.kr">HCI@KAIST</a> Winter Workshop. Received best poster award! </span><br>
                <span class="date">Dec 2017 :</span><span class="news"> Our RecipeScape paper is conditionally accepted to <a href="https://chi2018.acm.org/">CHI 2018</a>! </span><br>
                <span class="date">Oct 22 - 24, 2017 :</span><span class="news"> Student Volunteering for <a href="https://uist.acm.org/uist2017/">UIST 2017</a> @ Quebec City, QC, Canada </span><br>
                <span class="date">May 06 - 11, 2017 :</span><span class="news"> Student volunteering for <a href="https://chi2017.acm.org/">CHI 2017</a> @ Denver, CO, USA </span><br>
                <span class="date"> Feb 2017</span><span class="news"> Our LBW paper on large scale recipe mining as been accepted to  <a href="https://chi2017.acm.org/">CHI 2017</a>!</span><br>
                <span class="date"> Mar 2016</span><span class="news"> Started my journey in HCI research with <a href="https://juhokim.com">Juho!</a></span><br>
               
                </span>
                <span class="lessbutton" id="article00_less"> Less News </span>

            </div>
            <div class="col-md-2"> </div>
        </div>
        <!-- news row end-->
        
        
        <!-- pubs row -->
		<div id="fullpaper" class="row">
            
		    <div class="col-md-2"> </div>
            <div class="col-md-8">
                <div class="pub">Conference Papers</div>
                <!-- publication template 
                    <div class="eachpub">
                        <div class="meta">
                            <div class="conference"> </div>
                            <div class="title"> </div>
                            <div class="authors"> <b>Minsuk Chang</b> </div>
                        </div>
                        <div class="abstract">
                            
                            <span class="morebutton" id="article2"> Read More </span>
                            <span class="readmore" id="article2_content">
                            
                        
                            </span> 
                            <span class="lessbutton" id="article2_less"> Read Less </span>
                        </div>
                        <div class="links"> <a target="_blank" href=""> website </a>  &middot; <a target="_blank" href=""> pdf </a>
                        </div>
                    </div>
                -->
                <div class="eachpub">
                    <div class="meta">
                        <div class="conference"> CHI 2019 </div>
                        <div class="title"> How to Design Voice Based Navigation for How-To Videos</div>
                        <div class="authors"> <b> Minsuk Chang</b>, <a href="https://scholar.google.ca/citations?user=O3xpA-AAAAAJ">Ahn Truong</a>, <a href="http://www.oliverwang.info">Oliver Wang</a>, <a href="https://graphics.stanford.edu/~maneesh/">Maneesh Agrawala</a>, <a href="http://juhokim.com">Juho Kim</a> </div>
                    </div>
                    <div class="abstract">
                        <!-- what to show first -->
                        When watching how-to videos related to physical tasks, users’ hands are often occupied by the task, making voice input a natural fit. 
                        To better understand the design space of voice interactions for how-to video navigation, we conducted three think-aloud studies using: 
                        1) a traditional video interface, 2) a research probe providing a voice controlled video interface, and 3) a wizard-of-oz interface. 
                        <span class="morebutton" id="article3"> Read More </span>
                        <span class="readmore" id="article3_content">
                        <!-- rest of what to show on "more" -->
                        From the studies, we distill seven navigation objectives and their underlying intents: 
                        pace control pause, content alignment pause, video control pause, reference jump, replay jump, skip jump, and peek jump. 
                        Our analysis found that users’ navigation objectives and intents affect the choice of referent type and referencing approach in command utterances. 
                        Based on our findings, we recommend to 1) support conversational strategies like sequence expansions and command queues, 
                        2) allow users to identify and refine their navigation objectives explicitly, and 3) support the seven interaction intents.</span> 
                        <span class="lessbutton" id="article3_less"> Read Less </span>
                    </div>
                    <!-- <div class="keywords"> #HowtoVideos; #VoiceUserInterfaces #VideoInteraction </div>-->
                    <div class="links"> <a target="_blank" href="https://kixlab.github.io/website-files/2019/chi2019-VoiceVideoNavigation-paper.pdf"> pdf </a>
                    </div>
                </div>
                
            
                <div class="eachpub">
                    <div class="meta">
                        <div class="conference"> CHI 2018 </div>
                        <div class="title"> RecipeScape: An Interactive Tool for Analyzing Cooking Instructions at Scale </div>
                        <div class="authors"> <b> Minsuk Chang</b>, Leonore V. Guillain, <a href="https://hyeungshikjung.com/">Hyeungshik Jung</a>, Vivian M. Hare, <a href="https://juhokim.com">Juho Kim</a>, <a href="https://graphics.stanford.edu/~maneesh/">Maneesh Agrawala </a></div>
                    </div>

                    <div class="abstract">
                        <!-- what to show first -->
                        For cooking professionals and culinary students, understanding cooking instructions is an essential yet demanding task. 
                        Common tasks include categorizing different approaches to cooking a dish and identifying usage patterns of particular ingredients or cooking methods, 
                        all of which require extensive browsing and comparison. However, no existing system provides support for such in-depth and at-scale analysis.
                        <span class="morebutton" id="article2"> Read More </span>
                        <span class="readmore" id="article2_content">
                        <!-- rest of what to show on "more" -->
                        We present RecipeScape, an interactive system for browsing and analyzing the hundreds of recipes of a single dish available online. 
                        We also introduce a computational pipeline that extracts cooking processes from recipe text and calculates a procedural similarity between them.
                        To evaluate how RecipeScape supports culinary analysis at scale, 
                        we conducted a user study with cooking professionals and culinary students with 500 recipes for two different dishes. 
                        Results show that RecipeScape clusters recipes into distinct approaches, and captures notable usage patterns of ingredients and cooking actions.
                        </span> 
                        <span class="lessbutton" id="article2_less"> Read Less </span>
                    </div>
                    <!-- <div class="keywords"> <b>Keywords: </b>#InteractiveDataMining; #NaturallyCrowdsourcedData #ComputationalModels </div>-->
                    <div class="links"> <a target="_blank" href="https://recipescape.kixlab.org/"> website </a>  &middot; <a target="_blank" href="https://recipescape.kixlab.org/RecipeScape_CHI_2018__Camera_Ready_.pdf"> pdf </a>
                    </div>
                </div>
		    </div>  <!-- right col md 8 end -->
		  
		    <div class="col-md-2"> </div>
        </div>
        <!-- pubs row end-->
        
        <!-- LBW row -->
        <div id="posters" class="row">
            
            <div class="col-md-2"> </div>
            <div class="col-md-8"> 
                <div class="pub">Posters, Demos, Workshop Papers</div>
                <!-- publication template 
                    <div class="eachpub">
                        <div class="meta">
                            <div class="conference"> </div>
                            <div class="title"> </div>
                            <div class="authors"> <b>Minsuk Chang</b> </div>
                        </div>
                        <div class="abstract">
                            
                            <span class="morebutton" id="article2"> Read More </span>
                            <span class="readmore" id="article2_content">
                            
                        
                            </span> 
                            <span class="lessbutton" id="article2_less"> Read Less </span>
                        </div>
                        <div class="links"> <a target="_blank" href=""> website </a>  &middot; <a target="_blank" href=""> pdf </a>
                        </div>
                    </div>
                -->
                <div class="eachpub">
                    <div class="meta">
                        <div class="conference"> CHI 2019 LBW </div>
                        <div class="title"> SolveDeep: A System for Supporting Subgoal Learning in Online Math Problem Solving </div>
                        <div class="authors">Hyoungwook Jin, <b>Minsuk Chang</b>, <a href="https://juhokim.com">Juho Kim</a></div>
                    </div>
                    <div class="abstract">
                        <!-- what to show first -->
                        Learner-driven subgoal labeling helps learners form a hierarchical structure of solutions with subgoals, 
                        which are conceptual units of procedural problem solving.
                        While learning with such hierarchical structure of a solution in mind is effective in learning problem solving strategies, 
                        the development of an interactive feedback system to support subgoal labeling tasks at scale requires significant expert efforts,
                        making learner-driven subgoal labeling difficult to be applied in online learning environments. We propose SolveDeep, 
                        a system that provides feedback on learner solutions with peer-generated subgoals. 
                        <span class="morebutton" id="article4"> Read More </span>
                        <span class="readmore" id="article4_content">
                        <!-- rest of what to show on "more" -->
                        SolveDeep utilizes a learnersourcing workflow to generate the hierarchical representation of possible solutions, 
                        and uses a graph-alignment algorithm to generate a solution graph by merging the populated solution structures, 
                        which are then used to generate feedback on future learners' solutions. 
                        We conducted a user study with 7 participants to evaluate the efficacy of our system. 
                        Participants did subgoal learning with two math problems and rated the usefulness of system feedback. 
                        The average rating was 4.86 out of 7 (1: Not useful, 7: Useful), 
                        and the system could successfully construct a hierarchical structure of solutions with learnersourced subgoal labels.
                        </span> 
                        <span class="lessbutton" id="article4_less"> Read Less </span>
                    </div>
                    <!-- <div class="keywords"> #Learnersourcing; #SubgoalLearning; #ComputationalModels </div>-->
                    <div class="links"> <a target="_blank" href="files/chi19c-sub1497-cam-i15.pdf"> pdf </a></div>
                </div>
                    
                <div class="eachpub">
                    <div class="meta">
                        <div class="conference"> CHI 2018 Sensemaking Workshop</div>
                        <div class="title"> Sensemaking around How-to-cook Videos</div>
                        <div class="authors"> <b>Minsuk Chang</b>, Seayeon Lee, <a href="https://kyungjejo.com/"> Kyungje Jo</a>, <a href="https://juhokim.com">Juho Kim</a> </div>
                    </div>
                    <div class="abstract">
                        We conducted a series of exploratory studies on sensemaking behaviors people exhibit while watching how-to-cook
                        videos. The three different scenarios we examined are a) when people seek for alternatives in ingredients, tools and
                        actions, b) when people seek for explanations or more detail on certain instructions, and c) when people use text
                        search and when people use video when learning how to cook a dish. 
                        <span class="morebutton" id="article0"> Read More </span>
                        <span class="readmore" id="article0_content">
                        We found a) people often make arbitrary decisions on substituting ingredients, cooking tools, or cooking
                        actions while following instructions, b) people satisfice by verifying knowledge with little data and not wanting to deviate
                        from the initially chosen video, and c) people use text search for definitions and confirmation of substitutions while
                        they use video search for explanations and precise details for instruction steps
                        </span> 
                        <span class="lessbutton" id="article0_less"> Read Less </span>
                    </div>
                    <!-- <div class="keywords"> #HowtoVideos; #Sensemaking; #VideoInteraction  </div>-->
                    <div class="links"> <a target="_blank" href="https://sensemakingchi2018.com/"> workshop website </a>  &middot; <a target="_blank" href="files/Chang-SensemakingCookingVideos.pdf"> pdf </a>
                    </div>
                </div>

                <div class="eachpub">
                        <div class="meta">
                            <div class="conference"> CHI 2017 LBW </div>
                            <div class="title">RecipeScape: Mining and Analyzing Diverse Processes in Cooking Recipes</div>
                            <div class="authors"> <b>Minsuk Chang</b>, Vivian M. Hare, <a href="https://juhokim.com">Juho Kim</a>, <a href="https://graphics.stanford.edu/~maneesh/">Maneesh Agrawala </a></div>
                        </div>
                        <div class="abstract">
                            In culture analytics, it is important to ask fundamental questions that address salient characteristics of collective human behavior. 
                            This paper explores how analyzing cooking recipes in aggregate and at scale identifies these characteristics in the cooking culture, and answer
                            fundamental questions like ”what makes a chocolate chip cookie a chocolate chip cookie?”.                             
                            <span class="morebutton" id="article1"> Read More </span>
                            <span class="readmore" id="article1_content">
                            Aspiring cooks, professional chefs and cooking hobbyists share their recipes online resulting in thousands of different procedural instructions towards a shared goal. However, existing approaches
                            focus merely on analysis at the ingredient level, for example, extracting ingredient information from individual
                            recipes. We introduce RecipeScape, a prototype interface which supports visually querying, browsing and comparing cooking recipes at scale. We also present the underlying
                            computational pipeline of RecipeScape that scrapes recipes online, extracts their ingredient and instruction information, constructs a graphical representation, and computes similarity between pairs of recipes.
                            </span> 
                            <span class="lessbutton" id="article1_less"> Read Less </span>
                        </div>
                        <!-- <div class="keywords"> #InteractiveDataMining; #NaturallyCrowdsourcedData #ComputationalModels </div>-->
                        <div class="links"> <a target="_blank" href="https://recipescape.kixlab.org/"> website </a>  &middot; <a target="_blank" href="https://recipescape.kixlab.org/ea1524-chang.pdf"> pdf </a>
                        </div>
                    </div>
            </div>
            <div class="col-md-2"> </div>
        </div>
        <!-- news row end-->

        <!-- TMI row -->
        <div class="row">
            <div class="col-md-2"></div>
            <div class="col-md-8"> </div>
            <div class="col-md-2"> </div>
        </div>
	</div>




    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
    integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"
    integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"
    integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>
    <script defer src="https://use.fontawesome.com/releases/v5.0.6/js/all.js"></script>
    <!-- Include Google Analytics Here-->
    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
      
        ga('create', 'UA-77549813-1', 'auto');
        ga('send', 'pageview');
    </script>
</body>
</html>

